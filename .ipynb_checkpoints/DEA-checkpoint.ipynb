{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>healthassessmentid</th>\n",
       "      <th>assessment_date</th>\n",
       "      <th>n_assessment</th>\n",
       "      <th>assessment_number</th>\n",
       "      <th>final_assessment</th>\n",
       "      <th>assessment_year</th>\n",
       "      <th>assessment_type</th>\n",
       "      <th>assessment_quarter</th>\n",
       "      <th>assessment_month</th>\n",
       "      <th>...</th>\n",
       "      <th>imd_idaopi_score</th>\n",
       "      <th>glucose</th>\n",
       "      <th>tot_cholesterol</th>\n",
       "      <th>alcohol_consumption</th>\n",
       "      <th>regular_exercise</th>\n",
       "      <th>t2dm_nice</th>\n",
       "      <th>prediabetic</th>\n",
       "      <th>first_to_last</th>\n",
       "      <th>days_between_ha</th>\n",
       "      <th>years_between_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001EC929E1AB41684A7B5528628E4B7</td>\n",
       "      <td>0x97B5EB4313702E21828DD59E5BC4F085</td>\n",
       "      <td>13oct2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x0004022CC26B79C37471E953F521D0DC</td>\n",
       "      <td>0x786B53CCD0FF6397100F4080465628E0</td>\n",
       "      <td>01may2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x00044057F135CC6526BE752AD83115F6</td>\n",
       "      <td>0x6B04800E0E852F8C997D9AD8019B868E</td>\n",
       "      <td>13apr2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x000527A13F12637CFD34616163AFBC48</td>\n",
       "      <td>0xB0E4800F18AD1367A01658AA1A7736EF</td>\n",
       "      <td>12may2014</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x000527A13F12637CFD34616163AFBC48</td>\n",
       "      <td>0x6A1A149F1B99B942F3C3938A85799151</td>\n",
       "      <td>21mar2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            patientid                  healthassessmentid  \\\n",
       "0  0x0001EC929E1AB41684A7B5528628E4B7  0x97B5EB4313702E21828DD59E5BC4F085   \n",
       "1  0x0004022CC26B79C37471E953F521D0DC  0x786B53CCD0FF6397100F4080465628E0   \n",
       "2  0x00044057F135CC6526BE752AD83115F6  0x6B04800E0E852F8C997D9AD8019B868E   \n",
       "3  0x000527A13F12637CFD34616163AFBC48  0xB0E4800F18AD1367A01658AA1A7736EF   \n",
       "4  0x000527A13F12637CFD34616163AFBC48  0x6A1A149F1B99B942F3C3938A85799151   \n",
       "\n",
       "  assessment_date  n_assessment  assessment_number  final_assessment  \\\n",
       "0       13oct2017             1                  1                 1   \n",
       "1       01may2018             1                  1                 1   \n",
       "2       13apr2018             1                  1                 1   \n",
       "3       12may2014             2                  1                 0   \n",
       "4       21mar2016             2                  2                 1   \n",
       "\n",
       "   assessment_year  assessment_type  assessment_quarter  assessment_month  \\\n",
       "0             2017                1                   4                10   \n",
       "1             2018                4                   2                 5   \n",
       "2             2018                3                   2                 4   \n",
       "3             2014                4                   2                 5   \n",
       "4             2016                4                   1                 3   \n",
       "\n",
       "   ...  imd_idaopi_score  glucose  tot_cholesterol  alcohol_consumption  \\\n",
       "0  ...             0.024      3.8             4.68                    1   \n",
       "1  ...             0.110      5.3             6.20                    1   \n",
       "2  ...             0.120      5.6             6.10                    2   \n",
       "3  ...             0.071      5.9             4.60                    0   \n",
       "4  ...             0.071      5.3             4.40                    0   \n",
       "\n",
       "   regular_exercise  t2dm_nice  prediabetic  first_to_last  days_between_ha  \\\n",
       "0                 0          0            0            NaN              NaN   \n",
       "1                 1          0            0            NaN              NaN   \n",
       "2                 1          0            1            NaN              NaN   \n",
       "3                 1          0            1            NaN              NaN   \n",
       "4                 1          0            0            2.0            679.0   \n",
       "\n",
       "   years_between_ha  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               2.0  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with your actual file path\n",
    "df = pd.read_csv('./health.csv')\n",
    "\n",
    "# Display the first 5 rows to verify the data was loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117219"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Exploratory Data Analysis\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['prediabetic'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Check missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_data = pd.concat([missing_values, missing_percent], axis=1)\n",
    "missing_data.columns = ['Missing Values', 'Percentage']\n",
    "print(\"\\nFeatures with >50% missing values:\")\n",
    "print(missing_data[missing_data['Percentage'] > 50].sort_values('Percentage', ascending=False).head())\n",
    "\n",
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='prediabetic', data=df)\n",
    "plt.title('Distribution of Prediabetic Status')\n",
    "plt.xlabel('Prediabetic (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Remove features with too many missing values (>50%) and non-predictive columns\n",
    "cols_to_drop = missing_data[missing_data['Percentage'] > 50].index.tolist()\n",
    "cols_to_drop += ['patientid', 'healthassessmentid', 'assessment_date']  # Non-predictive columns\n",
    "X = df.drop(cols_to_drop + ['prediabetic'], axis=1)\n",
    "y = df['prediabetic']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "        ]), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Check for class imbalance and apply SMOTE if needed\n",
    "class_counts = y_train.value_counts()\n",
    "if class_counts[0] / class_counts[1] > 3 or class_counts[1] / class_counts[0] > 3:\n",
    "    print(\"\\nApplying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_preprocessed, y_train = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "    print(\"Class distribution after SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "# 3. Model Building and Evaluation\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate AUC-ROC if possible\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if auc_roc:\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance (if available)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importance(model, X, preprocessor, model_name)\n",
    "    \n",
    "    return model, accuracy, precision, recall, f1, auc_roc\n",
    "\n",
    "def feature_importance(model, X, preprocessor, model_name):\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        return\n",
    "        \n",
    "    # Get feature names\n",
    "    feature_names = []\n",
    "    for name, transformer, cols in preprocessor.transformers_:\n",
    "        if name == 'cat':\n",
    "            # Get the one-hot encoder\n",
    "            ohe = transformer.named_steps['onehot']\n",
    "            # Get all categories\n",
    "            categories = ohe.categories_\n",
    "            for i, category in enumerate(categories):\n",
    "                feature_names.extend([f\"{cols[i]}_{c}\" for c in category])\n",
    "        else:\n",
    "            feature_names.extend(cols)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Create DataFrame of features and importances\n",
    "    if len(importances) == len(feature_names):\n",
    "        feature_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "        feature_imp = feature_imp.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot top 20 features\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_imp.head(20))\n",
    "        plt.title(f'Top 20 Feature Importances - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, class_weight='balanced', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model_result = evaluate_model(model, X_train_preprocessed, y_train, X_test_preprocessed, y_test, name)\n",
    "    results[name] = model_result\n",
    "\n",
    "# Find best model based on AUC-ROC\n",
    "best_model_name = max(results, key=lambda x: results[x][5] if results[x][5] is not None else 0)\n",
    "best_model = results[best_model_name][0]\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "\n",
    "# 4. ROC Curve Comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (model, _, _, _, _, _) in results.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test_preprocessed)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Save best model results\n",
    "best_metrics = {\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': results[best_model_name][1],\n",
    "    'precision': results[best_model_name][2],\n",
    "    'recall': results[best_model_name][3],\n",
    "    'f1': results[best_model_name][4],\n",
    "    'auc_roc': results[best_model_name][5]\n",
    "}\n",
    "\n",
    "print(\"\\nBest Model Performance Summary:\")\n",
    "for metric, value in best_metrics.items():\n",
    "    if metric != 'model_name' and value is not None:\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
